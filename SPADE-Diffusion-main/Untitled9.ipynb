{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5282c42-90ca-47d4-9e6c-6ffe7fad6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前工作目录: /root/autodl-tmp/RPG-DiffusionMaster-main\n",
      "更改后的工作目录: /root/autodl-tmp/RPG-DiffusionMaster-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# 打印当前工作目录\n",
    "print(\"当前工作目录:\", os.getcwd())\n",
    "# 更改工作目录到指定路径\n",
    "os.chdir('/root/autodl-tmp/RPG-DiffusionMaster-main')\n",
    "# 再次打印当前工作目录以确认更改\n",
    "print(\"更改后的工作目录:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad0750d7-3019-42a6-8450-f1e079b7a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RegionalDiffusion_base import RegionalDiffusionPipeline\n",
    "from RegionalDiffusion_xl import RegionalDiffusionXLPipeline\n",
    "from diffusers.schedulers import KarrasDiffusionSchedulers,DPMSolverMultistepScheduler\n",
    "from mllm import local_llm,GPT4\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bf7a8c-be72-4309-a8c6-70db56d93a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint were not used when initializing CLIPTextModel: \n",
      " ['text_model.embeddings.position_ids']\n",
      "Some weights of the model checkpoint were not used when initializing CLIPTextModelWithProjection: \n",
      " ['text_model.embeddings.position_ids']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始init了！！！\n"
     ]
    }
   ],
   "source": [
    "pipe = RegionalDiffusionXLPipeline.from_single_file(\"../mod/albedobaseXL_v20.safetensors\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config,use_karras_sigmas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d5b7a8f-803d-4393-94cb-da65d9dc3271",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a838d47-3105-48b9-874f-089c4c3522e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= 'a bird on the left of a microwave'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd2bb0ad-3543-455c-bfd2-92f84917cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='/root/autodl-tmp/Llama2.13_1208'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107feebc-16bf-48e8-a351-814f7ed9f9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: /root/autodl-tmp/Llama2.13_1208\n"
     ]
    }
   ],
   "source": [
    "model_id=model_path\n",
    "print('Using model:',model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa4ce8a-87de-4051-8f24-7623f9010add",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: '/root/autodl-tmp/Llama2.13_1208'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/RPG/lib/python3.9/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/RPG/lib/python3.9/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/RPG/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/RPG/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/root/autodl-tmp/Llama2.13_1208'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaForCausalLM, LlamaTokenizer\n\u001b[0;32m----> 2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer ok!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/RPG/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1951\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vocab_files:\n\u001b[1;32m   1949\u001b[0m     \u001b[38;5;66;03m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m     fast_tokenizer_file \u001b[38;5;241m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[0;32m-> 1951\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1968\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   1969\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/RPG/lib/python3.9/site-packages/transformers/utils/hub.py:469\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/root/autodl-tmp/Llama2.13_1208'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "print(\"tokenizer ok!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5b1a701-f0e3-44f9-b281-e3b27cff4443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d5b65401794f9f98e14d890ff369c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ok!!\n"
     ]
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(model_id, load_in_8bit=False, device_map='auto', torch_dtype=torch.float16)\n",
    "print(\"model ok!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b19381-91b1-48aa-b8c4-f0c2492a9837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a master of composition who excels at extracting key objects and their attributes from input text and supplementing the original text with more detailed imagination, creating layouts that conform to human aesthetics. Your task is described as follows:\n",
      " \n",
      " Extract the key entities and their corresponding attributes from the input text, and determine how many regions should be splited.\n",
      " For each key object identified in the previous step, use precise spatial imagination to assign each object to a specific area within the image and start numbering from 0. The area refers to dividing the entire image into different regions for a general layout. Each key entities is assigned to a region. And for each entity in the region, give it a more detailed description based on the original text. This layout should segment the image and strictly follow the method below:\n",
      " a. Determine if the image needs to be divided into multiple rows (It should be noted that a single entity should not be split into different rows, except when describing different parts of a person like the head, clothes/body, and lower garment):\n",
      " • If so, segment the image into several rows and assign an identifier to each row from top to bottom (e.g., Row0, Row1, ...).\n",
      " • Specify the percentage of height each row occupies within the image (e.g., Row0 (height=0.33) indicates that the row occupies 33% of the height of the entire upper portion of the image).\n",
      " b. Within each row, further assess the need for division into multiple regions (it should be noted that each region should contain only one entity):\n",
      " • If required, divide each row from left to right into several blocks and assign a number to each block (e.g., Region0, Region1, ...).\n",
      " • Specify the percentage of width each block occupies within its respective row (e.g., Region0 (Row0, width=0.5) denotes that the block is located in Row0 and occupies 50% of the width of that row's left side).\n",
      " c. Output the overall ratio along with the regional prompts:\n",
      " • First, combine each row's height separated by semicolons like Row0_height; Row1_height; ...; Rown_height. If there is only one row, skip this step.\n",
      " • Secondly, attach each row's regions' width after each row's height separated with commas, like Row0_height,Row0_region0_width,Row0_region1_width,...Row0_regionm_width;Row1_height,Row1_region0_width,...;Rown_height,...Rown_regionj_width.\n",
      " • If the row doesn't have more than one region, just continue to the next row.\n",
      " • It should be noted that we should use decimal representation in the overall ratio, and if there is only one row, just omit the row ratio.\n",
      " The output should follow the format of the examples below:\n",
      " \n",
      " Examples:\n",
      " Caption: A green twintail hair girl wearing a white shirt printed with green apple and wearing a black skirt.\n",
      " Key entities identification:\n",
      " We only identify a girl with attribute: green hair twintail, red blouse, blue skirt, so we hierarchically split her features from top to down.\n",
      " 1). green hair twintail (head features of the girl)\n",
      " 2). red blouse (clothes and body features of the girl)\n",
      " 3). blue skirt (Lower garment)\n",
      " So we need to split the image into 3 subregions.\n",
      " Plan the structure split for the image:\n",
      " a. Rows\n",
      " Row0(height=0.33): Top 33% of the image, which is the head of the green twintail hair girl\n",
      " Row1(height=0.33): Middle 33% part of the image, the body of the girl which is the red blouse part\n",
      " Row2(height=0.33): Bottom 33% part of the lower body of the girl, which is the blue skirt\n",
      " There is no need to split each row into different regions, so each row is a subregion\n",
      " b. Regions with rows:\n",
      " Region0:(Row0,width=1) Lush green twintails cascade down, framing the girl's face with lively eyes and a subtle smile, accented by a few playful freckles\n",
      " Region1: (Row1,width=1) A vibrant red blouse, featuring ruffled sleeves and a cinched waist, adorned with delicate pearl buttons, radiates elegance\n",
      " Region2: (Row2,width=1) pleated blue skirt, knee-length, sways gracefully with each step, its fabric catching the light, paired with a slender white belt for a touch of sophistication.\n",
      " c. Overall ratio:\n",
      " Row0_height,(Row0_region0_width only one region in the row, skip); Row1_height,(Row1_region1_width only one region in the row, skip); Row2_height,(Row2_region2_width only one region in the row, skip)\n",
      " Final split ratio: 1;1;1\n",
      " Regional Prompt: Lush green twintails cascade down, framing the girl's face with lively eyes and a subtle smile, accented by a few playful freckles BREAK A vibrant red blouse, featuring ruffled sleeves and a cinched waist, adorned with delicate pearl buttons, radiates elegance BREAK pleated blue skirt, knee-length, sways gracefully with each step, its fabric catching the light, paired with a slender white belt for a touch of sophistication.\n",
      " \n",
      " Caption: A girl with white ponytail and black dress are chatting with a blonde curly hair girl in a white dress in a cafe.\n",
      " Key entities identification:\n",
      " We only identify two girls each with two attributes, #girl1(white ponytail,black dress) #girl2(blonde curly hair,blue skirt) so we hierarchically split their features from top to down.\n",
      " white ponytail (head features of the girl on the left)\n",
      " black dress (clothes features of the girl on the left)\n",
      " blonde curly hair (head features of the girl on the right)\n",
      " blue skirt (clothes of the girl on the right)\n",
      " Plan the structure split for the image:\n",
      " So we need to split the image into 4 subregions.\n",
      " a. Rows\n",
      " Since we have four key entities, we should split the image into 4 different regions, and two rows, the girls’ head in the top row, the girls’ body in the bottom row\n",
      " Row0 (height=0.5): Encompasses the heads and upper torsos of both women.\n",
      " Row1 (height=0.5): Includes the lower torsos of both women, down to where the table cuts across the image.\n",
      " b. Regions within rows\n",
      " Region0 (Row0, width=0.5): White ponytail girl, focusing on her sleek, flowing hair and the subtle expression of engagement in her conversation..\n",
      " Region1 (Row0, width=0.5): Blonde curly hair girl, emphasizing her vibrant curls and the lively sparkle in her eyes as she engages in the chat.\n",
      " Region2 (Row1, width=0.5): Her elegant black dress, highlighting the fabric's texture and any intricate details, like lace or embroidery.\n",
      " Region3 (Row1, width=0.5):Her white dress, capturing its flowy silhouette, possibly with floral patterns or delicate folds to accentuate its elegance.\n",
      " c. Overall ratio:\n",
      " Row0_height,Row0_region0_width,Row0_region1_width;Row1_height,Row1_region2_width,Row1_region3_wdith\n",
      " Final split ratio: 1,1,1;1,1,1\n",
      " Regional Prompt: Captures the woman in the black dress within the top half of the image. BREAK Contains the woman in the white blouse within the top half. BREAK Shows the lower half of the woman in the black dress. BREAK Displays the lower half of the woman in the white blouse.\n",
      " \n",
      " Caption Two girls are chatting in the cafe \n",
      " Key entities identification:\n",
      " The caption identifies two key entities without explicit attributes:\n",
      " Girl 1 (human subject, unspecified attributes)\n",
      " Girl 2 (human subject, unspecified attributes)\n",
      " Since no specific attributes are given for either girl, we will need to imagine details for each entity. We will split the image into two regions to represent each girl.\n",
      " \n",
      " Plan the structure split for the image:\n",
      " a. Rows\n",
      " Considering that we have two key entities and no specific attributes to separate vertically, we can choose to have a single row that encompasses both entities:\n",
      " Row0 (height=1): This row will occupy the entire image, showing both girls chatting in the cafe.\n",
      " \n",
      " b. Regions within rows\n",
      " We will divide the row into two regions to represent each girl:\n",
      " \n",
      " Region0 (Row0, width=0.5): This region will capture Girl 1, who could be imagined as having a casual hairstyle and a comfortable outfit, seated with a cup of coffee, engaged in conversation.\n",
      " Region1 (Row0, width=0.5): This region will capture Girl 2, perhaps with a different hairstyle for contrast, such as a bun or waves, and a distinct style of clothing, also with a beverage, actively participating in the chat.\n",
      " \n",
      " c. Overall ratio:\n",
      " Since there is only one row, we omit the row ratio and directly provide the widths of the regions within the row:\n",
      " Final split ratio: 0.5,0.5\n",
      " \n",
      " Regional Prompt: A casually styled Girl 1 with a warm smile, sipping coffee, her attention focused on her friend across the table, the background softly blurred with the ambiance of the cafe. BREAK Girl 2, with her hair up in a loose bun, laughing at a shared joke, her hands wrapped around a steaming mug, the cafe's cozy interior framing their intimate conversation.\n",
      " \n",
      " Caption:a bird on the left of a microwave \n",
      " Let's think step by step:\n"
     ]
    }
   ],
   "source": [
    "with open('template/template.txt', 'r') as f:\n",
    "        template=f.readlines()\n",
    "user_textprompt=f\"Caption:{prompt} \\n Let's think step by step:\"\n",
    "textprompt= f\"{' '.join(template)} \\n {user_textprompt}\"\n",
    "print(textprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd434a7-b1fd-45e8-8ed4-af6ead17e5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tokenizer(textprompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb15173-7b52-41cc-a5d0-ef4a4a4fc94e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuanming test 1119 waiting for GPT-4 response\n",
      "---------------------------------------------------------------------------------------------------\n",
      "To process the caption \"a bird on the left of a microwave,\" we begin by identifying the key entities and their attributes:\n",
      "\n",
      "### Key Entities Identification:\n",
      "1. **Bird**: The only attribute is its position, \"on the left.\"\n",
      "2. **Microwave**: No specific attributes are detailed beyond its position relative to the bird.\n",
      "\n",
      "Given these entities, we will split the image into the appropriate regions as follows:\n",
      "\n",
      "### Plan the Structure Split for the Image:\n",
      "\n",
      "#### a. Rows\n",
      "Since there are two key entities with distinct spatial relationships (the bird being on the left of the microwave), we will organize them horizontally within a single row:\n",
      "\n",
      "- **Row0 (height=1)**: Contains the entire scene including both the bird and the microwave. This row occupies 100% of the image height since there are no vertical separations needed.\n",
      "\n",
      "#### b. Regions within Rows\n",
      "We need to divide this single row into two regions, one for each entity:\n",
      "\n",
      "- **Region0 (Row0, width=0.5)**: This region will be dedicated to the bird positioned on the left side of the image. For additional detail, we might imagine a small domesticated bird with glossy feathers, perched confidently, its bright eyes scanning the room.\n",
      "  \n",
      "- **Region1 (Row0, width=0.5)**: This region will cover the microwave on the right side. Let's imagine it as a sleek, modern appliance with a shiny metallic finish, reflecting the light and resting securely on the kitchen counter.\n",
      "\n",
      "#### c. Overall Ratio:\n",
      "Since this layout contains only one row with two regions, we omit the row ratios and directly provide the widths of the regions within the row.\n",
      "\n",
      "- **Final split ratio: 0.5,0.5\n",
      "\n",
      "### Regional Prompt: A small domesticated bird with glossy feathers perched confidently on the counter, its bright eyes scanning the room. BREAK A sleek, modern microwave with a shiny metallic finish, reflecting the light and resting securely on the kitchen counter.\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "<class 'str'>\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "para_dict = GPT4(prompt,key='sk-UDZJFwAlNjn5bnQOOEJn8W7JXvm225kzvOXZARvVtuiQnPnR')\n",
    "#para_dict = local_llm(prompt,model_path='/root/autodl-tmp/Llama2.13_1208') \n",
    "#para_dict = local_llm(prompt,mod=model,tok=tokenizer,mod_input=model_input,txtpro=textprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8045c1-0138-4b37-b92a-ab6f887af49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5,0.5\n"
     ]
    }
   ],
   "source": [
    "split_ratio = para_dict['Final split ratio']    #获取字典中的Final split ratio:0.5,0.5,0.5;0.5,0.5,0.5\n",
    "print(split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde2977b-ca66-488f-96ff-2844b57aace9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small domesticated bird with glossy feathers perched confidently on the counter, its bright eyes scanning the room. BREAK A sleek, modern microwave with a shiny metallic finish, reflecting the light and resting securely on the kitchen counter.\n"
     ]
    }
   ],
   "source": [
    "regional_prompt = para_dict['Regional Prompt']      #获取字典中的Regional Prompt：每个区域的prompt\n",
    "print(regional_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08adbfc6-8040-4506-80f0-fa8d4309a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \"NSFW,worst quality,low quality,normal quality,lowres,monochrome,grayscale,skin spots,acnes,skin blemishes,age spot,ugly,duplicate,morbid,mutilated,tranny,mutated hands,poorly drawn hands,blurry,bad anatomy,bad proportions,extra limbs,disfigured,missing arms,extra legs,fused fingers,too many fingers,unclear eyes,lowers,bad hands,missing fingers,extra digit,bad hands,missing fingers,extra arms and legs\"    #没有negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7871de39-0a11-443a-94c0-6ff364ec8d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5, 0.5]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b3616c24704f86b8b74135f3b9791d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_seed = random.randint(0, 100000)\n",
    "images = pipe(\n",
    "    prompt=regional_prompt,\n",
    "    split_ratio=split_ratio, # The ratio of the regional prompt, the number of prompts is the same as the number of regions\n",
    "    batch_size = 1, #batch size\n",
    "    base_ratio = 0.5, # The ratio of the base prompt    \n",
    "    base_prompt= prompt,       \n",
    "    num_inference_steps=20, # sampling step\n",
    "    height = 1024, \n",
    "    negative_prompt=negative_prompt, # negative prompt\n",
    "    width = 1024, \n",
    "    seed = random_seed,# random seed\n",
    "    guidance_scale = 7.0\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27bf8244-d9f6-4a8c-a3da-7d584540600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.save(\"test1221.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93408ca7-c984-4498-affb-b99bbf4a83d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_number = str(random.randint(1, 9999)).zfill(6)\n",
    "save_path = os.path.join(\"/root/autodl-tmp/T2I-CompBench-main/examples/samples\", f\"{prompt}_{random_number}.png\")\n",
    "images.save(save_path)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21a633db-2e3d-4559-a33e-6ec37f0e16bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/autodl-tmp/T2I-CompBench-main/UniDet_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03624621-6c9c-409c-b7cc-9d652c6c371a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更改后的工作目录: /root/autodl-tmp/T2I-CompBench-main/UniDet_eval\n"
     ]
    }
   ],
   "source": [
    "print(\"更改后的工作目录:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad8c9595-cecd-4160-8e45-0fa85cce0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experts.obj_detection.generate_dataset import Dataset, collate_fn\n",
    "from experts.model_bank import load_expert_model\n",
    "from accelerate import Accelerator\n",
    "import argparse\n",
    "import ruamel.yaml as yaml\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import json\n",
    "obj_label_map = torch.load('dataset/detection_features.pt')['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3170c44e-0aaa-4ee4-8f30-6871dc14d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"UniDet evaluation.\")\n",
    "    parser.add_argument(\n",
    "        \"--outpath\",\n",
    "        type=str,\n",
    "        default=\"../examples/\",\n",
    "        help=\"Path to output score\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--complex\",\n",
    "        type=bool,\n",
    "        default=False,\n",
    "        help=\"Prompt is simple structure or in complex category\",\n",
    "    )\n",
    "    args = parser.parse_known_args()[0]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c494a6c-bae1-4f97-a981-9c265e73bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_labels(depth, instance_boxes, instance_id):\n",
    "    obj_masks = []\n",
    "    obj_ids = []\n",
    "    obj_boundingbox = []\n",
    "    for i in range(len(instance_boxes)):\n",
    "        is_duplicate = False\n",
    "        mask = torch.zeros_like(depth)\n",
    "        x1, y1, x2, y2 = instance_boxes[i][0].item(), instance_boxes[i][1].item(), \\\n",
    "                         instance_boxes[i][2].item(), instance_boxes[i][3].item()\n",
    "        mask[int(y1):int(y2), int(x1):int(x2)] = 1\n",
    "        if not is_duplicate:\n",
    "            obj_masks.append(mask)\n",
    "            obj_ids.append(instance_id[i])\n",
    "            obj_boundingbox.append([x1, y1, x2, y2])\n",
    "\n",
    "    instance_labels = {}\n",
    "    for i in range(len(obj_ids)):\n",
    "        instance_labels[i] = obj_ids[i].item()\n",
    "    return obj_boundingbox, instance_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdda7c2d-cf9b-436a-9249-154dd1afb857",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce8c54a1-df18-4d43-8df3-4f38e651a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/RPG/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Loading config experts/obj_detection/configs/Base-CRCNN-COCO.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n"
     ]
    }
   ],
   "source": [
    "model1, transform = load_expert_model(task='obj_detection', ckpt=\"RS200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72826bcf-471a-4fc6-9906-73ca8f163a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "accelerator = Accelerator(mixed_precision='fp16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6ace132-7541-48bb-8b55-2cc2dc5937b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open('configs/experts.yaml', 'r'), Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ec313ba-b7ee-47cb-9284-26f70de4f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = args.outpath\n",
    "data_path= outpath\n",
    "save_path= f'{outpath}/labels'\n",
    "batch_size = 64\n",
    "dataset = Dataset(data_path,  transform)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "model1, data_loader = accelerator.prepare(model1, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ae81a28-f4c4-46c3-807c-bd0b44604d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'couch', 'studio couch', 'sofa bed', 'chair', 'crosswalk', 'pillow', 'bed', 'dog bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9937, 0.9751, 0.9590, 0.7671, 0.6987, 0.4734, 0.3555, 0.3262, 0.2917,\n",
      "        0.1807, 0.1492, 0.1368, 0.1323], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2484130859375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'pillow', 'furniture', 'houseplant, potted plant', 'couch', 'sofa bed', 'studio couch', 'cat', 'animal', 'picture, frame', 'pillow', 'bed', 'carnivore', 'furniture', 'picture, frame', 'lynx', 'crosswalk']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9917, 0.9790, 0.9556, 0.8555, 0.8125, 0.7954, 0.7944, 0.5449, 0.4873,\n",
      "        0.4111, 0.2783, 0.2114, 0.2050, 0.1953, 0.1776, 0.1727, 0.1635, 0.1167,\n",
      "        0.1052, 0.1028], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2479248046875\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'furniture', 'couch', 'sofa bed', 'studio couch', 'houseplant, potted plant', 'pillow', 'bed', 'chair', 'window', 'lynx', 'tree', 'crosswalk']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9810, 0.9746, 0.9233, 0.7246, 0.7246, 0.3801, 0.3682, 0.3328, 0.2749,\n",
      "        0.2452, 0.1182, 0.1154, 0.1089, 0.1066, 0.1057, 0.1032],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2452392578125\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'sofa bed', 'studio couch', 'couch', 'chair', 'bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9858, 0.9668, 0.9019, 0.8618, 0.8022, 0.6001, 0.5425, 0.5288, 0.2228,\n",
      "        0.1069], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2464599609375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'loveseat, couch', 'furniture', 'couch', 'pillow', 'sofa bed', 'studio couch', 'flower', 'street light']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9937, 0.9824, 0.9575, 0.9507, 0.6782, 0.5913, 0.3069, 0.3035, 0.2142,\n",
      "        0.1615, 0.1449, 0.1290], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2484130859375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'houseplant, potted plant', 'loveseat, couch', 'furniture', 'couch', 'sofa bed', 'studio couch', 'pillow', 'tree']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9883, 0.9771, 0.9551, 0.9507, 0.7710, 0.7207, 0.5444, 0.4688, 0.3738,\n",
      "        0.2654, 0.1024], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2470703125\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'chair', 'couch']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9868, 0.9688, 0.9180, 0.3184, 0.1864, 0.1144, 0.1021],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2467041015625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'houseplant, potted plant', 'furniture', 'loveseat, couch', 'vase', 'sofa bed', 'vase', 'couch', 'studio couch', 'animal', 'cat', 'table, desk', 'carnivore', 'flowerpot', 'pillow', 'bed', 'flower', 'furniture', 'pillow', 'lynx', 'furniture']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9946, 0.9868, 0.9731, 0.9199, 0.8809, 0.8706, 0.6836, 0.6665, 0.6133,\n",
      "        0.6108, 0.5928, 0.3208, 0.3137, 0.2805, 0.2766, 0.2140, 0.2037, 0.1472,\n",
      "        0.1461, 0.1252, 0.1215, 0.1069, 0.1061], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2486572265625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'loveseat, couch', 'pillow', 'furniture', 'sofa bed', 'couch', 'studio couch', 'animal', 'cat', 'carnivore', 'pillow', 'houseplant, potted plant', 'pillow', 'bed', 'lynx', 'furniture', 'crosswalk', 'towel, napkin']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9946, 0.9858, 0.9673, 0.9297, 0.9077, 0.8555, 0.7798, 0.6616, 0.6226,\n",
      "        0.5894, 0.3005, 0.2874, 0.2032, 0.1943, 0.1752, 0.1307, 0.1298, 0.1201,\n",
      "        0.1039, 0.1028, 0.1027], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2486572265625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'studio couch', 'sofa bed', 'chair', 'couch', 'lynx']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9941, 0.9868, 0.9526, 0.8164, 0.6172, 0.4258, 0.3801, 0.3464, 0.3245,\n",
      "        0.1155], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.24853515625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'couch', 'studio couch', 'sofa bed', 'chair', 'bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9961, 0.9829, 0.9702, 0.7681, 0.6733, 0.3926, 0.3760, 0.3486, 0.1840,\n",
      "        0.1074], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2490234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'lamp', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'picture, frame', 'lamp', 'sofa bed', 'studio couch', 'couch', 'furniture', 'pillow', 'pole', 'chair', 'pillow']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9858, 0.9819, 0.9751, 0.9282, 0.6187, 0.5298, 0.3545, 0.2996, 0.2932,\n",
      "        0.2903, 0.2659, 0.2137, 0.2123, 0.1442, 0.1375, 0.1136],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2464599609375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'furniture', 'couch', 'sofa bed', 'studio couch', 'houseplant, potted plant', 'pillow', 'lynx', 'bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9946, 0.9780, 0.9624, 0.8301, 0.7422, 0.5327, 0.4460, 0.4121, 0.3955,\n",
      "        0.1816, 0.1265, 0.1260], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2486572265625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'furniture', 'sofa bed', 'studio couch', 'couch', 'pillow']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9897, 0.9868, 0.9546, 0.6152, 0.4902, 0.3333, 0.2771, 0.2695, 0.1232],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2474365234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'loveseat, couch', 'furniture', 'picture, frame', 'couch', 'sofa bed', 'studio couch', 'houseplant, potted plant', 'bed', 'lynx', 'pillow', 'furniture']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9902, 0.9849, 0.9609, 0.9009, 0.8477, 0.8359, 0.6665, 0.6089, 0.5449,\n",
      "        0.4602, 0.3008, 0.1696, 0.1205, 0.1153, 0.1081], device='cuda:0',\n",
      "       dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.24755859375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'pillow', 'carnivore', 'furniture', 'loveseat, couch', 'couch', 'chair', 'chair', 'sofa bed', 'studio couch', 'furniture', 'pillow']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9897, 0.9722, 0.9316, 0.9038, 0.6040, 0.5327, 0.2712, 0.1724, 0.1637,\n",
      "        0.1633, 0.1405, 0.1381, 0.1368], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2474365234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'houseplant, potted plant', 'carnivore', 'table, desk', 'coffee table', 'furniture', 'pillow', 'vase', 'coffee table', 'vase', 'furniture', 'flowerpot', 'loveseat, couch', 'lynx', 'chair']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9946, 0.9917, 0.9780, 0.9629, 0.5322, 0.5088, 0.5088, 0.4326, 0.3564,\n",
      "        0.3232, 0.2688, 0.2382, 0.2172, 0.1915, 0.1382, 0.1037],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2486572265625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'furniture', 'loveseat, couch', 'pillow', 'sofa bed', 'studio couch', 'couch', 'pillow', 'cat', 'animal', 'pillow', 'loveseat, couch', 'carnivore', 'furniture', 'pillow']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9961, 0.9863, 0.9741, 0.9604, 0.8867, 0.8770, 0.8735, 0.6431, 0.6167,\n",
      "        0.5537, 0.3818, 0.2394, 0.2238, 0.1724, 0.1523, 0.1498, 0.1344, 0.1180],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2490234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['lamp', 'furniture', 'studio couch', 'animal', 'sofa bed', 'loveseat, couch', 'carnivore', 'cat', 'table, desk', 'furniture', 'couch', 'coffee table', 'coffee table', 'bed', 'pillow', 'pillow', 'pillow', 'lamp', 'table, desk', 'vase', 'furniture', 'lamp']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9648, 0.9634, 0.9453, 0.9438, 0.9380, 0.9370, 0.9272, 0.9160, 0.7500,\n",
      "        0.7500, 0.6958, 0.6812, 0.6235, 0.4551, 0.4131, 0.3281, 0.2311, 0.2230,\n",
      "        0.2085, 0.1670, 0.1346, 0.1011], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.22900390625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['lamp', 'cat', 'animal', 'carnivore', 'furniture', 'picture, frame', 'loveseat, couch', 'studio couch', 'couch', 'sofa bed', 'furniture', 'coffee table', 'furniture', 'table, desk', 'nightstand', 'chair', 'animal', 'bed', 'coffee table', 'lamp', 'cat', 'furniture', 'table, desk', 'coffee table', 'stool', 'carnivore', 'chair', 'crosswalk']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9878, 0.9849, 0.9614, 0.9297, 0.8638, 0.8569, 0.7480, 0.5396, 0.5190,\n",
      "        0.4797, 0.4099, 0.3948, 0.3242, 0.2734, 0.2456, 0.2362, 0.2201, 0.1802,\n",
      "        0.1783, 0.1569, 0.1471, 0.1302, 0.1281, 0.1248, 0.1208, 0.1138, 0.1126,\n",
      "        0.1086], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2462158203125\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'lamp', 'animal', 'carnivore', 'pillow', 'furniture', 'pole', 'loveseat, couch', 'lamp', 'pillow', 'pillow', 'lamp', 'studio couch', 'sofa bed', 'pillow', 'chair', 'couch', 'pillow', 'pillow', 'lynx']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9858, 0.9746, 0.9741, 0.9336, 0.6323, 0.5552, 0.3909, 0.3867, 0.2979,\n",
      "        0.2742, 0.2703, 0.2430, 0.2159, 0.1885, 0.1798, 0.1637, 0.1611, 0.1383,\n",
      "        0.1256, 0.1122], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2464599609375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'furniture', 'loveseat, couch', 'pillow', 'couch', 'pillow', 'sofa bed', 'studio couch', 'pillow', 'chair']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9897, 0.9722, 0.9165, 0.8462, 0.6255, 0.6255, 0.3972, 0.3174, 0.3064,\n",
      "        0.2598, 0.2561, 0.2104, 0.1160], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2474365234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'houseplant, potted plant', 'pillow', 'sofa bed', 'couch', 'studio couch', 'pillow', 'bed', 'pillow', 'furniture', 'tree', 'loveseat, couch', 'animal']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9897, 0.9761, 0.9497, 0.9067, 0.9048, 0.7583, 0.7407, 0.7124, 0.6895,\n",
      "        0.6851, 0.2673, 0.1492, 0.1246, 0.1223, 0.1130, 0.1125, 0.1097],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2474365234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'pillow', 'furniture', 'houseplant, potted plant', 'couch', 'sofa bed', 'studio couch', 'cat', 'animal', 'picture, frame', 'pillow', 'bed', 'carnivore', 'furniture', 'picture, frame', 'lynx', 'crosswalk']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9917, 0.9790, 0.9556, 0.8555, 0.8125, 0.7954, 0.7944, 0.5449, 0.4873,\n",
      "        0.4111, 0.2783, 0.2114, 0.2050, 0.1953, 0.1776, 0.1727, 0.1635, 0.1167,\n",
      "        0.1052, 0.1028], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2479248046875\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'couch', 'studio couch', 'sofa bed', 'chair']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9858, 0.9712, 0.9214, 0.7329, 0.6255, 0.3904, 0.3127, 0.3081, 0.2347],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2464599609375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'houseplant, potted plant', 'loveseat, couch', 'pillow', 'couch', 'sofa bed', 'studio couch', 'chair', 'lynx', 'bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9966, 0.9863, 0.9692, 0.8047, 0.7612, 0.7593, 0.5562, 0.5293, 0.4441,\n",
      "        0.4324, 0.1276, 0.1255, 0.1182], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2491455078125\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'loveseat, couch', 'furniture', 'couch', 'sofa bed', 'studio couch', 'pillow', 'loveseat, couch', 'loveseat, couch', 'furniture', 'bed', 'furniture', 'lynx', 'couch', 'couch', 'sofa bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9941, 0.9858, 0.9722, 0.9692, 0.9312, 0.9116, 0.8027, 0.7651, 0.7075,\n",
      "        0.4316, 0.3291, 0.2433, 0.1771, 0.1724, 0.1705, 0.1505, 0.1451, 0.1273,\n",
      "        0.1085], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.24853515625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'pillow', 'furniture', 'pillow', 'pillow', 'pillow', 'loveseat, couch', 'chair', 'pillow']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9937, 0.9824, 0.9360, 0.5933, 0.3760, 0.3738, 0.3401, 0.2507, 0.2461,\n",
      "        0.2030, 0.1603], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2484130859375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'houseplant, potted plant', 'carnivore', 'furniture', 'loveseat, couch', 'couch', 'sofa bed', 'studio couch', 'vase', 'vase', 'animal', 'pillow', 'furniture', 'loveseat, couch', 'cat', 'flowerpot', 'carnivore', 'bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9937, 0.9819, 0.9712, 0.9629, 0.8711, 0.8647, 0.6597, 0.5913, 0.5117,\n",
      "        0.4082, 0.3945, 0.2812, 0.2590, 0.2527, 0.1742, 0.1710, 0.1605, 0.1467,\n",
      "        0.1126], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2484130859375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'pillow', 'furniture', 'couch', 'pillow', 'sofa bed', 'studio couch', 'pillow', 'chair', 'bed']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9907, 0.9790, 0.9478, 0.8726, 0.8594, 0.8579, 0.6030, 0.5576, 0.5508,\n",
      "        0.4983, 0.2524, 0.1464, 0.1298], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2476806640625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'furniture', 'loveseat, couch', 'pillow', 'studio couch', 'sofa bed', 'couch', 'vase', 'picture, frame', 'pillow', 'chair', 'vase', 'pillow', 'bed', 'vase', 'animal', 'pillow', 'carnivore', 'animal', 'cat']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9941, 0.9849, 0.9668, 0.8979, 0.8833, 0.6714, 0.6655, 0.6470, 0.6128,\n",
      "        0.6094, 0.2634, 0.2583, 0.2467, 0.2372, 0.1969, 0.1570, 0.1312, 0.1272,\n",
      "        0.1113, 0.1043, 0.1017, 0.1003], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.24853515625\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'furniture', 'pillow', 'pillow', 'sofa bed', 'studio couch', 'couch', 'pillow', 'pillow', 'bed', 'lynx', 'animal', 'pillow', 'carnivore', 'crosswalk']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9961, 0.9907, 0.9785, 0.9604, 0.9556, 0.9497, 0.9277, 0.8696, 0.8394,\n",
      "        0.7246, 0.4668, 0.3105, 0.1886, 0.1713, 0.1375, 0.1348, 0.1226, 0.1138],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2490234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n",
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'furniture', 'pillow', 'couch', 'sofa bed', 'lynx', 'studio couch']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9927, 0.9868, 0.9668, 0.5386, 0.4993, 0.3757, 0.2615, 0.1896, 0.1387,\n",
      "        0.1368], device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2481689453125\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "普通场景\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:23<00:00, 23.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****检测到的物体如下:*****\n",
      "['cat', 'animal', 'carnivore', 'loveseat, couch', 'furniture', 'couch', 'sofa bed', 'studio couch', 'lynx']\n",
      "*****物体的分数如下*****\n",
      "tensor([0.9961, 0.9868, 0.9780, 0.7417, 0.6782, 0.4626, 0.3176, 0.2903, 0.1798],\n",
      "       device='cuda:0', dtype=torch.float16)\n",
      "*****原始语句*****\n",
      "a cat on the top of a sofa\n",
      "这哥们只有obj1！\n",
      "=======================\n",
      "0.2490234375\n",
      "=======================\n",
      "=======================\n",
      "0\n",
      "=======================\n",
      "vqa result saved in ../examples//labels/annotation_obj_detection_2d\n",
      "--------------------------------------------------------------------------------------------\n",
      "[{'question_id': 2, 'answer': 0}, {'question_id': 1139, 'answer': 0}, {'question_id': 1391, 'answer': 0}, {'question_id': 1655, 'answer': 0}, {'question_id': 1993, 'answer': 0}, {'question_id': 2468, 'answer': 0}, {'question_id': 2674, 'answer': 0}, {'question_id': 2690, 'answer': 0}, {'question_id': 3641, 'answer': 0}, {'question_id': 4085, 'answer': 0}, {'question_id': 4156, 'answer': 0}, {'question_id': 5331, 'answer': 0}, {'question_id': 5495, 'answer': 0}, {'question_id': 5801, 'answer': 0}, {'question_id': 5817, 'answer': 0}, {'question_id': 5961, 'answer': 0}, {'question_id': 6114, 'answer': 0}, {'question_id': 6144, 'answer': 0}, {'question_id': 6592, 'answer': 0}, {'question_id': 6749, 'answer': 0}, {'question_id': 6813, 'answer': 0}, {'question_id': 6962, 'answer': 0}, {'question_id': 7175, 'answer': 0}, {'question_id': 7700, 'answer': 0}, {'question_id': 7799, 'answer': 0}, {'question_id': 7804, 'answer': 0}, {'question_id': 7891, 'answer': 0}, {'question_id': 8329, 'answer': 0}, {'question_id': 8797, 'answer': 0}, {'question_id': 8997, 'answer': 0}, {'question_id': 9163, 'answer': 0}, {'question_id': 9584, 'answer': 0}, {'question_id': 9786, 'answer': 0}, {'question_id': 9895, 'answer': 0}]\n",
      "avg score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " with torch.no_grad():\n",
    "        result = []\n",
    "        map_result = []\n",
    "        for i, test_data in enumerate(tqdm(data_loader)):\n",
    "            #print(\"-----------------------------------------------------------------------------------------\")\n",
    "            #print(i)\n",
    "            #print(\"-----------------------------------------------------------------------------------------\")\n",
    "            test_pred = model1(test_data)\n",
    "            for k in range(len(test_pred)):\n",
    "                #print(test_pred[k])\n",
    "                instance_boxes = test_pred[k]['instances'].get_fields()['pred_boxes'].tensor  # get the bbox of list\n",
    "                instance_id = test_pred[k]['instances'].get_fields()['pred_classes']\n",
    "                depth = test_data[k]['image'][0]\n",
    "\n",
    "                # get score\n",
    "                instance_score = test_pred[k]['instances'].get_fields()['scores']\n",
    "\n",
    "                obj_bounding_box, obj_labels_dict = get_mask_labels(depth, instance_boxes, instance_id)\n",
    "                #print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "                #print(obj_bounding_box)\n",
    "                #print(obj_labels_dict)\n",
    "                #print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "                obj = []\n",
    "                for i in range(len(obj_bounding_box)):\n",
    "                    obj_name = obj_label_map[obj_labels_dict[i]]\n",
    "                    obj.append(obj_name)\n",
    "\n",
    "\n",
    "                img_path_split = test_data[k]['image_path'].split('/')\n",
    "                prompt = img_path_split[-1].split('_')[0] # get prompt from file names\n",
    "                vocab_spatial = ['on side of', 'next to', 'near', 'on the left of', 'on the right of', 'on the bottom of', 'on the top of','on top of'] #locality words\n",
    "\n",
    "                locality = None\n",
    "                for word in vocab_spatial:\n",
    "                    if word in prompt:\n",
    "                        locality = word\n",
    "                        break\n",
    "\n",
    "                if (args.complex):\n",
    "                    #for complex structure\n",
    "                    nlp = spacy.load('en_core_web_sm')\n",
    "                    # Define the sentence\n",
    "                    sentence = prompt\n",
    "                    # Process the sentence using spaCy\n",
    "                    doc = nlp(sentence)\n",
    "                    # Define the target prepositions\n",
    "                    prepositions = [\"on top of\", \"on bottom of\", \"on the left\", \"on the right\",'next to','on side of','near']\n",
    "                    # Extract objects before and after the prepositions\n",
    "                    objects = []\n",
    "                    for i in range(len(doc)):\n",
    "                        if doc[i:i + 3].text in prepositions or doc[i:i + 2].text in prepositions or doc[i:i + 1].text in prepositions:\n",
    "                            if doc[i:i + 3].text in prepositions:\n",
    "                                k=3\n",
    "                            elif doc[i:i + 2].text in prepositions:\n",
    "                                k=2\n",
    "                            elif doc[i:i + 1].text in prepositions:\n",
    "                                k=1\n",
    "                            preposition_phrase = doc[i:i + 3].text\n",
    "                            for j in range(i - 1, -1, -1):\n",
    "                                if doc[j].pos_ == 'NOUN':\n",
    "                                    objects.append(doc[j].text)\n",
    "                                    break\n",
    "                                elif doc[j].pos_ == 'PROPN':\n",
    "                                    objects.append(doc[j].text)\n",
    "                                    break\n",
    "                            flag=False\n",
    "                            for j in range(i + k, len(doc)):\n",
    "                                if doc[j].pos_ == 'NOUN':\n",
    "                                    objects.append(doc[j].text)\n",
    "                                    break\n",
    "                                if(j==len(doc)-1):\n",
    "                                    flag=True\n",
    "                            if flag:\n",
    "                                for j in range(i + k, len(doc)):\n",
    "                                    if (j+1<len(doc)) and doc[j].pos_ == 'PROPN' and doc[j+1].pos_ != 'PROPN':\n",
    "                                        objects.append(doc[j].text)\n",
    "                                        break\n",
    "                    if (len(objects)==2):\n",
    "                        obj1=objects[0]\n",
    "                        obj2=objects[1]\n",
    "                    else:\n",
    "                        obj1=None\n",
    "                        obj2=None\n",
    "                else:\n",
    "                    print(\"普通场景\")\n",
    "                    #for simple structure\n",
    "                    nlp = spacy.load(\"en_core_web_sm\")\n",
    "                    doc = nlp(prompt)\n",
    "                    obj1= [token.text for token in doc if token.pos_=='NOUN'][0]\n",
    "                    obj2= [token.text for token in doc if token.pos_=='NOUN'][-1]\n",
    "\n",
    "                person = ['girl','boy','man','woman']\n",
    "                if obj1 in person:\n",
    "                    obj1 = \"person\"\n",
    "                if obj2 in person:\n",
    "                    obj2 = \"person\"\n",
    "                print(\"*****检测到的物体如下:*****\")\n",
    "                print(obj)\n",
    "                print(\"*****物体的分数如下*****\")\n",
    "                print(instance_score)\n",
    "                print(\"*****原始语句*****\")\n",
    "                print(prompt)\n",
    "                if obj1 in obj and obj2 in obj:\n",
    "                    print(\"这哥们两个都有！\")\n",
    "                    obj1_pos = obj.index(obj1)\n",
    "                    obj2_pos = obj.index(obj2)\n",
    "                    obj1_bb = obj_bounding_box[obj1_pos]\n",
    "                    obj2_bb = obj_bounding_box[obj2_pos]\n",
    "                    box1, box2={},{}\n",
    "                    box1[\"x_min\"] = obj1_bb[0]\n",
    "                    box1[\"y_min\"] = obj1_bb[1]\n",
    "                    box1[\"x_max\"] = obj1_bb[2]\n",
    "                    box1[\"y_max\"] = obj1_bb[3]\n",
    "                    box2[\"x_min\"] = obj2_bb[0]\n",
    "                    box2[\"y_min\"] = obj2_bb[1]\n",
    "                    box2[\"x_max\"] = obj2_bb[2]\n",
    "                    box2[\"y_max\"] = obj2_bb[3]\n",
    "                    print(\"*****第一个物体是*****\")\n",
    "                    print(obj1)\n",
    "                    print(\"分数\")\n",
    "                    print(instance_score[obj1_pos].item())\n",
    "                    print(\"*****第二个物体是*****\")\n",
    "                    print(obj2)\n",
    "                    print(\"分数\")\n",
    "                    print(instance_score[obj2_pos].item())\n",
    "                    print(\"*****获取到的空间信息*****\")\n",
    "                    print(locality)\n",
    "\n",
    "                    score = 0.25 * instance_score[obj1_pos].item() + 0.25 * instance_score[obj2_pos].item()  # score = avg across two objects score\n",
    "                    print(\"这哥们不算位置分\",score)\n",
    "                    score += determine_position(locality, box1, box2) / 2\n",
    "                    print(\"这哥们算位置分\",score)\n",
    "                elif obj1 in obj:\n",
    "                    print(\"这哥们只有obj1！\")\n",
    "                    obj1_pos = obj.index(obj1)\n",
    "                    score = 0.25 * instance_score[obj1_pos].item()\n",
    "                elif obj2 in obj:\n",
    "                    print(\"这哥们只有obj2！\")\n",
    "                    obj2_pos = obj.index(obj2)\n",
    "                    score = 0.25 * instance_score[obj2_pos].item()\n",
    "                else:\n",
    "                    score = 0\n",
    "                print(\"=======================\")\n",
    "                print(score)\n",
    "                print(\"=======================\")\n",
    "                if (score<0.5):\n",
    "                    score=0\n",
    "                print(\"=======================\")\n",
    "                print(score)\n",
    "                print(\"=======================\")\n",
    "\n",
    "                image_dict = {}\n",
    "                image_dict['question_id']=int(img_path_split[-1].split('_')[-1].split('.')[0])\n",
    "                image_dict['answer'] = score\n",
    "                result.append(image_dict)\n",
    "\n",
    "                # add mapping\n",
    "                map_dict = {}\n",
    "                map_dict['image'] = img_path_split[-1]\n",
    "                map_dict['question_id']=int(img_path_split[-1].split('_')[-1].split('.')[0])\n",
    "                map_result.append(map_dict)\n",
    "        im_save_path = os.path.join(save_path, 'annotation_obj_detection_2d')\n",
    "        os.makedirs(im_save_path, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(im_save_path, 'vqa_result.json'), 'w') as f:\n",
    "            json.dump(result, f)\n",
    "        print('vqa result saved in {}'.format(im_save_path))\n",
    "\n",
    "        # avg score\n",
    "        avg_score = 0\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        print(result)\n",
    "        for i in range(len(result)):\n",
    "            avg_score+=float(result[i]['answer'])\n",
    "        with open(os.path.join(im_save_path, 'avg_score.txt'), 'w') as f:\n",
    "            f.write('score avg:'+str(avg_score/len(result)))\n",
    "        print(\"avg score:\",avg_score/len(result))\n",
    "\n",
    "        # save mapping\n",
    "        with open(os.path.join(im_save_path, 'mapping.json'), 'w') as f:\n",
    "            json.dump(map_result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e509b376-eeb5-4250-8050-d832b113bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39fe7b29-7d6e-4fc9-a5eb-faecee0c58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/root/autodl-tmp/T2I-CompBench-main/examples/labels/annotation_obj_detection_2d/avg_score.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bce2bba-3fb9-4215-a001-49cf0e2097f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        # 读取文件内容\n",
    "        content = file.read()\n",
    "        # 查找包含\"score avg:\"的行\n",
    "        for line in content.splitlines():\n",
    "            if \"score avg:\" in line:\n",
    "                # 提取分数（假设分数紧跟在\"score avg:\"之后，且可能有空格分隔）\n",
    "                score_str = line.split(\":\")[-1].strip()  # 去除冒号后的部分，并去除首尾空格\n",
    "                # 尝试将分数转换为浮点数\n",
    "                sco = float(score_str)\n",
    "                break  # 找到分数后退出循环\n",
    "except FileNotFoundError:\n",
    "    print(f\"文件 {file_path} 未找到。\")\n",
    "except ValueError:\n",
    "    print(\"无法将分数转换为浮点数。\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c3304e5-d65c-4f3c-a23a-6f81a7e6421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分数是: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 打印结果\n",
    "if sco is not None:\n",
    "    print(f\"分数是: {sco}\")\n",
    "else:\n",
    "    print(\"未能从文件中获取分数。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5416741-3655-41f3-9a23-ef88303bb171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "还不行\n",
      "循环了10次，无论如何都退出了。\n",
      "最终 sco 的值是: 0.0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    " \n",
    "while counter < 10:\n",
    "    print(\"还不行\")\n",
    "    # 增加计数器\n",
    "    counter += 1\n",
    "    if sco != 0:\n",
    "         break\n",
    "    \n",
    "    # 可选：在这里可以添加一些延迟（比如 sleep）来模拟实际工作中的等待时间\n",
    "    time.sleep(1)  # 等待1秒\n",
    " \n",
    "# 当计数器达到 10 时，自动退出循环\n",
    "# 注意：由于我们没有改变 sco 的值，所以实际上是因为计数器达到了 10 才退出的循环\n",
    "print(\"循环了10次，无论如何都退出了。\")\n",
    " \n",
    "# 如果你希望在循环退出后检查 sco 的值，可以在这里进行\n",
    "# 但在这个例子中，sco 的值仍然是 0\n",
    "print(f\"最终 sco 的值是: {sco}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ff4ba99-1881-4a7d-b01e-e1c439af1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa09e258-3ed8-40b6-82f1-bef842a24cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccb0104-b699-47f6-bb56-4038dac3d853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_position(locality, box1, box2, iou_threshold=0.1,distance_threshold=150):\n",
    "    # Calculate centers of bounding boxes\n",
    "    box1_center = ((box1['x_min'] + box1['x_max']) / 2, (box1['y_min'] + box1['y_max']) / 2)\n",
    "    box2_center = ((box2['x_min'] + box2['x_max']) / 2, (box2['y_min'] + box2['y_max']) / 2)\n",
    "\n",
    "    # Calculate horizontal and vertical distances\n",
    "    x_distance = box2_center[0] - box1_center[0]\n",
    "    y_distance = box2_center[1] - box1_center[1]\n",
    "    print(\"box1:\",box1_center,\"box2:\",box2_center)\n",
    "    print(\"x_distance:\",x_distance,\"y_distance:\",y_distance)\n",
    "    # Calculate IoU\n",
    "    x_overlap = max(0, min(box1['x_max'], box2['x_max']) - max(box1['x_min'], box2['x_min']))\n",
    "    y_overlap = max(0, min(box1['y_max'], box2['y_max']) - max(box1['y_min'], box2['y_min']))\n",
    "    intersection = x_overlap * y_overlap\n",
    "    box1_area = (box1['x_max'] - box1['x_min']) * (box1['y_max'] - box1['y_min'])\n",
    "    box2_area = (box2['x_max'] - box2['x_min']) * (box2['y_max'] - box2['y_min'])\n",
    "    union = box1_area + box2_area - intersection\n",
    "    iou = intersection / union\n",
    "    print(\"交并比:\",iou)\n",
    "\n",
    "    # Determine position based on distances and IoU and give a soft score\n",
    "    score=0\n",
    "    if locality in ['next to', 'on side of', 'near']:\n",
    "        if (abs(x_distance)< distance_threshold or abs(y_distance)< distance_threshold):\n",
    "            score=1\n",
    "        else:\n",
    "            score=distance_threshold/max(abs(x_distance),abs(y_distance))\n",
    "    elif locality == 'on the right of':\n",
    "        if x_distance < 0:\n",
    "            if abs(x_distance) > abs(y_distance) and iou < iou_threshold:\n",
    "                score=1\n",
    "            elif abs(x_distance) > abs(y_distance) and iou >= iou_threshold:\n",
    "                score=iou_threshold/iou\n",
    "        else:\n",
    "            score=0\n",
    "    elif locality == 'on the left of':\n",
    "        if x_distance > 0:\n",
    "            if abs(x_distance) > abs(y_distance) and iou < iou_threshold:\n",
    "                score=1\n",
    "            elif abs(x_distance) > abs(y_distance) and iou >= iou_threshold:\n",
    "                score=iou_threshold/iou\n",
    "        else:\n",
    "            score=0\n",
    "    elif locality =='on the bottom of':\n",
    "        if y_distance < 0:\n",
    "            if abs(y_distance) > abs(x_distance) and iou < iou_threshold:\n",
    "                score=1\n",
    "            elif abs(y_distance) > abs(x_distance) and iou >= iou_threshold:\n",
    "                score=iou_threshold/iou\n",
    "    elif locality =='on the top of':\n",
    "        if y_distance > 0:\n",
    "            if abs(y_distance) > abs(x_distance) and iou < iou_threshold:\n",
    "                score=1\n",
    "            elif abs(y_distance) > abs(x_distance) and iou >= iou_threshold:\n",
    "                score=iou_threshold/iou\n",
    "    else:\n",
    "        score=0\n",
    "    print(\"位置得分:\",score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b195f-9fc4-409c-8dcf-58b566f57f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RPGyuanming",
   "language": "python",
   "name": "rpgyuanming"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
